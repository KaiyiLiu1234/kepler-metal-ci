{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# ------------------ EDIT ONLY HERE ------------------------\n",
    "branch = 'modelServer'\n",
    "#branch = 'main'\n",
    "date = '2024-07-30'  # Replace with anything from 2024-07-26\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Base URL and date\n",
    "base_url = 'https://github.com/sustainable-computing-io/kepler-metal-ci/tree/{branch}/docs/validation/{date}/'\n",
    "\n",
    "# JSON file names\n",
    "json_files = {\n",
    "    'vm': 'kepler_node_package_joules_total--dynamic.json',\n",
    "    'metal': 'kepler_vm_package_joules_total--dynamic.json'\n",
    "}\n",
    "\n",
    "# Python Code to replace MAPE\n",
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100\n",
    "\n",
    "# Fetch the HTML content for the given date\n",
    "date_url = base_url.format(branch=branch, date=date)\n",
    "response = requests.get(date_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Find the script tag containing the JSON data\n",
    "    script_tag = soup.find('script', {'type': \"application/json\", 'data-target': \"react-app.embeddedData\"})\n",
    "    if script_tag:\n",
    "        # Extract the JSON data and parse it\n",
    "        json_data = json.loads(script_tag.string)\n",
    "\n",
    "        folder_names = [item['name'] for item in json_data.get('payload', {}).get('tree', {}).get('items', []) if item.get('contentType') == 'directory']\n",
    "\n",
    "        # Process each folder (report ID)\n",
    "        for folder_name in folder_names:\n",
    "            # Construct base URL for the current folder's JSON files (using raw.githubusercontent.com)\n",
    "            folder_url = f'https://raw.githubusercontent.com/sustainable-computing-io/kepler-metal-ci/{branch}/docs/validation/{date}/{folder_name}/'\n",
    "\n",
    "            df_metal = None\n",
    "            df_vm = None\n",
    "\n",
    "            # Process each known JSON file\n",
    "            for data_type, json_file in json_files.items():\n",
    "                json_url = folder_url + json_file\n",
    "                response = requests.get(json_url)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    timestamps = data['timestamps']\n",
    "                    values = data['values']\n",
    "\n",
    "                    timestamps = [datetime.datetime.fromtimestamp(ts) for ts in timestamps]\n",
    "\n",
    "                    # Create DataFrame and assign to corresponding variable\n",
    "                    if data_type == 'metal':\n",
    "                        df_metal = pd.DataFrame({'Timestamp': timestamps, 'Watts': values})\n",
    "                    elif data_type == 'vm':\n",
    "                        df_vm = pd.DataFrame({'Timestamp': timestamps, 'Watts': values})\n",
    "                else:\n",
    "                    print(f\"Failed to fetch data for {json_file} in folder {folder_name}\")\n",
    "\n",
    "            # Plot the data if both node and VM data were fetched successfully\n",
    "            if df_metal is not None and df_vm is not None:\n",
    "\n",
    "                # Calculate the MSE and MAPE values aligning on the timeline\n",
    "                df_merged = pd.merge(df_metal, df_vm, on='Timestamp', how='inner', suffixes=('_metal', '_vm'))\n",
    "\n",
    "                # Calculate MSE and MAPE using the merged DataFrame \n",
    "                mse = mean_squared_error(df_merged['Watts_metal'], df_merged['Watts_vm'])\n",
    "                mape = mean_absolute_percentage_error(df_merged['Watts_metal'], df_merged['Watts_vm'])\n",
    "\n",
    "                fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "                # Plot node data on the first y-axis (ax1)\n",
    "                ax1.plot(df_metal['Timestamp'], df_metal['Watts'], marker='x', color='#024abf', label='metal data')\n",
    "                ax1.set_xlabel('Timestamp')\n",
    "                ax1.set_ylabel('Metal [Watts]', color='#024abf')\n",
    "                ax1.tick_params(axis='y')\n",
    "\n",
    "                # Create a second y-axis (ax2) sharing the same x-axis\n",
    "                ax2 = ax1.twinx()\n",
    "\n",
    "                # Plot VM data on the second y-axis (ax2)\n",
    "                ax2.plot(df_vm['Timestamp'], df_vm['Watts'], marker='o', color='#ff742e', label='vm data')\n",
    "                ax2.set_ylabel('VM [Watts]', color='#ff742e')\n",
    "                ax2.tick_params(axis='y')\n",
    "\n",
    "                # Title and grid\n",
    "                plt.title(f'Kepler Metal & VM / {folder_name} / Branch: {branch} / Date: {date}')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.grid(True)\n",
    "\n",
    "                # Combine legends from both axes\n",
    "                lines, labels = ax1.get_legend_handles_labels()\n",
    "                lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "                ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "                textstr = f'MSE: {mse:.2f}\\nMAPE: {mape:.2f}%'\n",
    "                ax1.text(0.98, 0.97, textstr, transform=ax1.transAxes, fontsize=14,\n",
    "                         verticalalignment='top', horizontalalignment='right',\n",
    "                         bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to fetch data for date {date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
